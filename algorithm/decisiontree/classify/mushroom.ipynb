{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02c0140b-92e7-4ad7-a6cb-bd776b850c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70af179-4719-46db-90c6-421da63ea18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index = None, threshold = None, left = None, right = None, information_gain = None, value = None):\n",
    "        # decision node\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.information_gain = information_gain\n",
    "        \n",
    "        #leaf node\n",
    "        self.value = value     \n",
    "        \n",
    "        \n",
    "\n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_sample_splits = 2, max_depth = 2):\n",
    "        #Khởi tạo root\n",
    "        self.root = None\n",
    "        \n",
    "        #Điều kiện dừng của cây\n",
    "        self.min_sample_splits = min_sample_splits \n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # train cây\n",
    "        dataset = np.concatenate((X, Y), axis = 1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "        \n",
    "        \n",
    "    def calculate_info_gain(self, parent, left_child, right_child, mode = \"entropy\"):\n",
    "        \n",
    "        #Trọng số (weight): mối liên hệ giữa số quan sát của tập con với tập cha\n",
    "        weight_left = len(left_child) / len(parent)\n",
    "        weight_right = len(right_child) / len(parent)\n",
    "        \n",
    "        if (mode == \"gini\"):\n",
    "            gini_index_left = self.gini_index(left_child)\n",
    "            gini_index_right = self.gini_index(right_child)\n",
    "            gini_index_parent = self.gini_index(parent)\n",
    "            \n",
    "            gain = gini_index_parent - (weight_left * gini_index_left + weight_right * gini_index_right)\n",
    "        else:\n",
    "            entropy_parent = self.entropy(parent)\n",
    "            entropy_left = self.entropy(left_child)\n",
    "            entropy_right = self.entropy(right_child)\n",
    "            \n",
    "            gain = entropy_parent - (weight_left * entropy_left + weight_right * entropy_right)\n",
    "            \n",
    "        return gain\n",
    "    \n",
    "    \n",
    "    def entropy(self, y):\n",
    "        data_labels = np.unique(y) # Lấy ra các giá trị ko trùng lặp của data (1, 1, 1, 0) => (1, 0)\n",
    "        entropy = 0\n",
    "        \n",
    "        for label in data_labels:\n",
    "            p_label = len(y[y == label]) / len(y) # Xác suất xuất hiện y = label trong tập y (1, 1, 1, 0) => p_1 = 3/4\n",
    "            entropy += ( - p_label * np.log2(p_label) )\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y): # Tương tự như hàm entropy\n",
    "        data_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        \n",
    "        for label in data_labels:\n",
    "            p_label = len(y[y == label]) / len(y)\n",
    "            gini += p_label**2\n",
    "        \n",
    "        return 1 - gini\n",
    "    \n",
    "    \n",
    "    def build_tree(self, dataset, current_depth = 0):\n",
    "        # Tách biến thuộc tính và mục tiêu làm 2 biến X, Y\n",
    "        X = dataset[ : , : -1] # Chọn tất cả các hàng và cột trừ cột cuối cùng (Ko có cột type)\n",
    "        Y = dataset[ : , -1] # Chọn tất cả hàng nhưng chỉ lấy cột cuối cùng (Cột type)\n",
    "        \n",
    "        # Lấy ra số lượng quan sát và số biến thuộc tính (Sử dụng np.shape(data))\n",
    "        num_samples, num_features = np.shape(X) # np.shape(X) trả về số hàng và cột của X \n",
    "        \n",
    "        # Tiếp tục tách cây nếu như thỏa mãn điều kiện dưới\n",
    "        if (num_samples >= self.min_sample_splits and current_depth <= self.max_depth):\n",
    "            \n",
    "            #Tìm ra cách tách tốt nhất\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            \n",
    "            #Kiểm tra xem information gain có lớn hơn 0 hay ko (= 0 thì node đó sẽ chứa cùng 1 kiểu dữ liệu => leaf node)\n",
    "            if (best_split[\"information_gain\"] > 0):\n",
    "                \n",
    "                left_tree = self.build_tree(best_split[\"dataset_left\"], current_depth + 1)\n",
    "                right_tree = self.build_tree(best_split[\"dataset_right\"], current_depth + 1)\n",
    "                \n",
    "                #Trả về decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_tree, right_tree, best_split[\"information_gain\"])\n",
    "            \n",
    "        # Gặp điều kiện dừng => Node sẽ trở thành leaf node\n",
    "        \n",
    "        ## Tính toán giá trị leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "\n",
    "        # Trả về leaf node \n",
    "        return Node(value = leaf_value)\n",
    "    \n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        # Tạo ra một dictionary để lưu giá trị\n",
    "        best_split = {} \n",
    "        \n",
    "        # Khởi tạo max information gain\n",
    "        max_information_gain = -1 \n",
    "        \n",
    "        # Duyệt hết các biến thuộc tính (feature)\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[ : , feature_index] # Lấy ra tất cả các hàng ở cột thứ feature_index\n",
    "            # => thu được một mảng các giá trị của biến feature thứ index\n",
    "            \n",
    "            #Coi mỗi giá trị của biến feature là một threshold (ngưỡng giá trị) để chia dữ liệu\n",
    "            unique_thresholds = np.unique(feature_values) # Loại bỏ các giá trị trùng lặp\n",
    "            \n",
    "            #Duyệt tất cả các giá trị của feature (thresholds) có trong data\n",
    "            for threshold in unique_thresholds:\n",
    "                #Tách dataset thành 2 phần tại giá trị threshold\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                \n",
    "                #Kiểm tra xem 2 bộ dataset vừa tách ra có null hay không\n",
    "                if (len(dataset_left) > 0 and len(dataset_right) > 0):\n",
    "                    \n",
    "                    # Lấy ra các biến mục tiêu theo 3 bộ data lần lượt\n",
    "                    y = dataset[ : , -1] #biến mục tiêu gốc\n",
    "                    left_y = dataset_left[ : , -1] #biến mục tiêu dataset_left\n",
    "                    right_y = dataset_right[ : , -1] #biến mục tiêu dataset_right\n",
    "                    \n",
    "                    #Tính toán information gain\n",
    "                    current_information_gain = self.calculate_info_gain(y, left_y, right_y, \"gini\")\n",
    "                    \n",
    "                    #update best split nếu thỏa mãn điều kiện dưới\n",
    "                    if (current_information_gain > max_information_gain):\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"information_gain\"] = current_information_gain\n",
    "                        \n",
    "                        #update max information gain\n",
    "                        max_information_gain = current_information_gain\n",
    "                \n",
    "        return best_split\n",
    "    \n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        \n",
    "        rows_left = []\n",
    "        rows_right = []\n",
    "        \n",
    "        # Tách dataset của biến feature thứ index thành 2 phần dựa theo threshold\n",
    "        for row in dataset:\n",
    "            if (row[feature_index] <= threshold):\n",
    "                rows_left.append(row)\n",
    "            else:\n",
    "                rows_right.append(row)\n",
    "        \n",
    "        #convert từ array sang np.array\n",
    "        dataset_left = np.array(rows_left)\n",
    "        dataset_right = np.array(rows_right)\n",
    "        \n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key = Y.count)\n",
    "                \n",
    "    \n",
    "    def print_preorder_tree(self, tree = None, indent = \"   \"):\n",
    "        if (not tree):\n",
    "            tree = self.root\n",
    "        \n",
    "        if (tree.value is not None):\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"X_\" + str(tree.feature_index), \"<=\", tree.threshold,\"?\", tree.information_gain)\n",
    "            print(\"%sleft: \" %(indent), end = \"\")\n",
    "            self.print_preorder_tree(tree.left, indent + indent)\n",
    "            print(\"%sright: \" %(indent), end = \"\")\n",
    "            self.print_preorder_tree(tree.right, indent + indent)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        \n",
    "        if (tree.value != None):\n",
    "            return tree.value\n",
    "        \n",
    "        feature_value = x[tree.feature_index]\n",
    "        if (feature_value <= tree.threshold):\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3c8312-a248-4e01-bce8-19715f5b62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\ADMIN\\\\Desktop\\\\study\\\\algorithm\\\\decisiontree\\\\datasets\\\\mushrooms.csv\")\n",
    "name_cols = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87eb9657-6634-4241-9496-5f6ada3fc3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "for feature in data:\n",
    "    if (feature != \"class\"):\n",
    "        data[feature] = encoder.fit_transform(data[feature])\n",
    "\n",
    "    \n",
    "x = data.loc[:, data.columns != \"class\"].to_numpy()\n",
    "y = data.iloc[:, 0].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8f7ab-4c60-4a20-9adb-eeed7be790c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c24d0-cff2-48fc-b21f-c886d6d16d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
