{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6f1643-ac24-430a-b334-4fe16ce42ee2",
   "metadata": {},
   "source": [
    "# TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3bdc6a-9cc1-4e91-9268-4a1c99d00f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf17f7e9-1c03-4836-9baf-bf02bc68cad7",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df2a344b-3ac7-458c-b8f7-4711669b0d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width    type\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa\n",
       "5           5.4          3.9           1.7          0.4  Setosa\n",
       "6           4.6          3.4           1.4          0.3  Setosa\n",
       "7           5.0          3.4           1.5          0.2  Setosa\n",
       "8           4.4          2.9           1.4          0.2  Setosa\n",
       "9           4.9          3.1           1.5          0.1  Setosa"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"type\"]\n",
    "data = pd.read_csv(\"iris.csv\", skiprows = 1, names = col_names)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ca6ce-da0b-4418-8001-2cbf36819b11",
   "metadata": {},
   "source": [
    "# Node class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064cfb5-5540-4f35-afbc-178fab7c0cf3",
   "metadata": {},
   "source": [
    "- Có 2 loại Node: \n",
    "    - Decision node: \n",
    "        - Điều kiện: bao gồm feature_index (thuộc tính) và threshold (ngưỡng giá trị của thuộc tính)\n",
    "        - left, right\n",
    "        - information gain\n",
    "    - Leaf node: value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4875a30f-055a-4364-a45e-411d5f8870c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index = None, threshold = None, left = None, right = None, information_gain = None, value = None):\n",
    "        # decision node\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.information_gain = information_gain\n",
    "        \n",
    "        #leaf node\n",
    "        self.value = value     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711951d0-81ab-4d2c-a70b-c2b3fbe1f4c2",
   "metadata": {},
   "source": [
    "## Tree class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993569a-a222-4ac2-a4e0-ec4ce264ca3a",
   "metadata": {},
   "source": [
    "- Root: gốc\n",
    "- min_sample_splits: Nếu như số quan sát trong 1 Node < giá trị min_sample_split thì sẽ không phân nhánh Node đó ra nữa.\n",
    "    => Coi node đó như là một leaf node\n",
    "- max_depth: Nếu như độ sâu của cây đạt đến max_depth thì chúng ta sẽ không phân nhánh node ra nữa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de1b9985-e754-44be-9e70-ba0ae1113832",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_sample_splits = 2, max_depth = 2):\n",
    "        #Khởi tạo root\n",
    "        self.root = None\n",
    "        \n",
    "        #Điều kiện dừng của cây\n",
    "        self.min_sample_splits = min_sample_splits \n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # train cây\n",
    "        dataset = np.concatenate((X, Y), axis = 1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "        \n",
    "        \n",
    "    def calculate_info_gain(self, parent, left_child, right_child, mode = \"entropy\"):\n",
    "        \n",
    "        #Trọng số (weight): mối liên hệ giữa số quan sát của tập con với tập cha\n",
    "        weight_left = len(left_child) / len(parent)\n",
    "        weight_right = len(right_child) / len(parent)\n",
    "        \n",
    "        if (mode == \"gini\"):\n",
    "            gini_index_left = self.gini_index(left_child)\n",
    "            gini_index_right = self.gini_index(right_child)\n",
    "            gini_index_parent = self.gini_index(parent)\n",
    "            \n",
    "            gain = gini_index_parent - (weight_left * gini_index_left + weight_right * gini_index_right)\n",
    "        else:\n",
    "            entropy_parent = self.entropy(parent)\n",
    "            entropy_left = self.entropy(left_child)\n",
    "            entropy_right = self.entropy(right_child)\n",
    "            \n",
    "            gain = entropy_parent - (weight_left * entropy_left + weight_right * entropy_right)\n",
    "            \n",
    "        return gain\n",
    "    \n",
    "    \n",
    "    def entropy(self, y):\n",
    "        data_labels = np.unique(y) # Lấy ra các giá trị ko trùng lặp của data (1, 1, 1, 0) => (1, 0)\n",
    "        entropy = 0\n",
    "        \n",
    "        for label in data_labels:\n",
    "            p_label = len(y[y == label]) / len(y) # Xác suất xuất hiện y = label trong tập y (1, 1, 1, 0) => p_1 = 3/4\n",
    "            entropy += ( - p_label * np.log2(p_label) )\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "    def gini_index(self, y): # Tương tự như hàm entropy\n",
    "        data_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        \n",
    "        for label in data_labels:\n",
    "            p_label = len(y[y == label]) / len(y)\n",
    "            gini += p_label**2\n",
    "        \n",
    "        return 1 - gini\n",
    "    \n",
    "    \n",
    "    def build_tree(self, dataset, current_depth = 0):\n",
    "        # Tách biến thuộc tính và mục tiêu làm 2 biến X, Y\n",
    "        X = dataset[ : , : -1] # Chọn tất cả các hàng và cột trừ cột cuối cùng (Ko có cột type)\n",
    "        Y = dataset[ : , -1] # Chọn tất cả hàng nhưng chỉ lấy cột cuối cùng (Cột type)\n",
    "        \n",
    "        # Lấy ra số lượng quan sát và số biến thuộc tính (Sử dụng np.shape(data))\n",
    "        num_samples, num_features = np.shape(X) # np.shape(X) trả về số hàng và cột của X \n",
    "        \n",
    "        # Tiếp tục tách cây nếu như thỏa mãn điều kiện dưới\n",
    "        if (num_samples >= self.min_sample_splits and current_depth <= self.max_depth):\n",
    "            \n",
    "            #Tìm ra cách tách tốt nhất\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            \n",
    "            #Kiểm tra xem information gain có lớn hơn 0 hay ko (= 0 thì node đó sẽ chứa cùng 1 kiểu dữ liệu => leaf node)\n",
    "            if (best_split[\"information_gain\"] > 0):\n",
    "                \n",
    "                left_tree = self.build_tree(best_split[\"dataset_left\"], current_depth + 1)\n",
    "                right_tree = self.build_tree(best_split[\"dataset_right\"], current_depth + 1)\n",
    "                \n",
    "                #Trả về decision node\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], left_tree, right_tree, best_split[\"information_gain\"])\n",
    "            \n",
    "        # Gặp điều kiện dừng => Node sẽ trở thành leaf node\n",
    "        \n",
    "        ## Tính toán giá trị leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "\n",
    "        # Trả về leaf node \n",
    "        return Node(value = leaf_value)\n",
    "    \n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        # Tạo ra một dictionary để lưu giá trị\n",
    "        best_split = {} \n",
    "        \n",
    "        # Khởi tạo max information gain\n",
    "        max_information_gain = -1 \n",
    "        \n",
    "        # Duyệt hết các biến thuộc tính (feature)\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[ : , feature_index] # Lấy ra tất cả các hàng ở cột thứ feature_index\n",
    "            # => thu được một mảng các giá trị của biến feature thứ index\n",
    "            \n",
    "            #Coi mỗi giá trị của biến feature là một threshold (ngưỡng giá trị) để chia dữ liệu\n",
    "            unique_thresholds = np.unique(feature_values) # Loại bỏ các giá trị trùng lặp\n",
    "            \n",
    "            #Duyệt tất cả các giá trị của feature (thresholds) có trong data\n",
    "            for threshold in unique_thresholds:\n",
    "                #Tách dataset thành 2 phần tại giá trị threshold\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                \n",
    "                #Kiểm tra xem 2 bộ dataset vừa tách ra có null hay không\n",
    "                if (len(dataset_left) > 0 and len(dataset_right) > 0):\n",
    "                    \n",
    "                    # Lấy ra các biến mục tiêu theo 3 bộ data lần lượt\n",
    "                    y = dataset[ : , -1] #biến mục tiêu gốc\n",
    "                    left_y = dataset_left[ : , -1] #biến mục tiêu dataset_left\n",
    "                    right_y = dataset_right[ : , -1] #biến mục tiêu dataset_right\n",
    "                    \n",
    "                    #Tính toán information gain\n",
    "                    current_information_gain = self.calculate_info_gain(y, left_y, right_y, \"gini\")\n",
    "                    \n",
    "                    #update best split nếu thỏa mãn điều kiện dưới\n",
    "                    if (current_information_gain > max_information_gain):\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"information_gain\"] = current_information_gain\n",
    "                        \n",
    "                        #update max information gain\n",
    "                        max_information_gain = current_information_gain\n",
    "                \n",
    "        return best_split\n",
    "    \n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        \n",
    "        rows_left = []\n",
    "        rows_right = []\n",
    "        \n",
    "        # Tách dataset của biến feature thứ index thành 2 phần dựa theo threshold\n",
    "        for row in dataset:\n",
    "            if (row[feature_index] <= threshold):\n",
    "                rows_left.append(row)\n",
    "            else:\n",
    "                rows_right.append(row)\n",
    "        \n",
    "        #convert từ array sang np.array\n",
    "        dataset_left = np.array(rows_left)\n",
    "        dataset_right = np.array(rows_right)\n",
    "        \n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        Y = list(Y)\n",
    "        return max(Y, key = Y.count)\n",
    "                \n",
    "    \n",
    "    def print_preorder_tree(self, tree = None, indent = \"   \"):\n",
    "        if (not tree):\n",
    "            tree = self.root\n",
    "        \n",
    "        if (tree.value is not None):\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"X_\" + str(tree.feature_index), \"<=\", tree.threshold,\"?\", tree.information_gain)\n",
    "            print(\"%sleft: \" %(indent), end = \"\")\n",
    "            self.print_preorder_tree(tree.left, indent + indent)\n",
    "            print(\"%sright: \" %(indent), end = \"\")\n",
    "            self.print_preorder_tree(tree.right, indent + indent)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        predictions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        \n",
    "        if (tree.value != None):\n",
    "            return tree.value\n",
    "        \n",
    "        feature_value = x[tree.feature_index]\n",
    "        if (feature_value <= tree.threshold):\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c976b6-f8c2-4487-9bf4-bf1e0c0933b6",
   "metadata": {},
   "source": [
    "## Chia data thành 2 bộ train và test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ad8a075-b24c-4515-b5ab-67706c820cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[ : , : -1].values\n",
    "Y = data.iloc[ : , -1].values.reshape(-1, 1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b75ca-eef8-47a6-b849-f526b5affdb3",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17ff8592-ae9c-4440-a406-bb79f6b373a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_2 <= 1.9 ? 0.30657596371882084\n",
      "   left: Setosa\n",
      "   right: X_3 <= 1.7 ? 0.4008080808080807\n",
      "      left: X_2 <= 5.1 ? 0.07870916961826062\n",
      "            left: X_0 <= 4.9 ? 0.02046485260770972\n",
      "                        left: Versicolor\n",
      "                        right: Versicolor\n",
      "            right: Virginica\n",
      "      right: Virginica\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(min_sample_splits = 3, max_depth = 3)\n",
    "dt_classifier.fit(X_train, Y_train)\n",
    "dt_classifier.print_preorder_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "af94593e-c6e7-4649-87d7-b0fc16eec4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = dt_classifier.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f42c76-672d-47cb-be33-8f135ab7c829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a775031-f3f2-4f4e-8388-e306a2891097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
